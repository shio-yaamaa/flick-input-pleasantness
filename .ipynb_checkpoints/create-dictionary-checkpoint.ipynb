{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook creates a dictionary out of the vocabulary provided by 実用日本語表現辞典."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# String utility\n",
    "\n",
    "import re\n",
    "\n",
    "hiragana_re = re.compile(r'[ぁ-ん]')\n",
    "\n",
    "# Uncomment the second line if the provided text uses \"う゛\" instead of \"ゔ\"\n",
    "def hiragana2katakana(hiragana):\n",
    "    #hiragana = hiragana.replace('う゛', 'ヴ')\n",
    "    return hiragana_re.sub(lambda x: chr(ord(x.group(0)) + 0x60), hiragana)\n",
    "\n",
    "def has_katakana_only(string):\n",
    "    match = re.match(\"^[ァ-ヴ]*$\", string)\n",
    "    return match is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Website information\n",
    "\n",
    "ROOT_PATH = 'https://www.weblio.jp/category/dictionary/jtnhj/'\n",
    "\n",
    "initial_letters = [\n",
    "    'aa', 'ii', 'uu', 'ee', 'oo',\n",
    "    'ka', 'ki', 'ku', 'ke', 'ko',\n",
    "    'sa', 'shi', 'su', 'se', 'so',\n",
    "    'ta', 'chi', 'tsu', 'te', 'to',\n",
    "    'na', 'ni', 'nu', 'ne', 'no',\n",
    "    'ha', 'hi', 'fu', 'he', 'ho',\n",
    "    'ma', 'mi', 'mu', 'me', 'mo',\n",
    "    'ya', 'yu', 'yo',\n",
    "    'ra', 'ri', 'ru', 're', 'ro',\n",
    "    'wa', 'wo', 'nn',\n",
    "    'ga', 'gi', 'gu', 'ge', 'go',\n",
    "    'za', 'zi', 'zu', 'ze', 'zo',\n",
    "    'da', 'du', 'de', 'do', # 'di' doesn't exist\n",
    "    'ba', 'bi', 'bu', 'be', 'bo',\n",
    "    'pa', 'pi', 'pu', 'pe', 'po'\n",
    "]\n",
    "\n",
    "# Different pages are in different directories as in 'hiragana/13'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scraping\n",
    "\n",
    "import time\n",
    "from requests import get\n",
    "from requests.exceptions import RequestException\n",
    "from contextlib import closing # For with construction\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_html(url):\n",
    "    try:\n",
    "        with closing(get(url, stream=True)) as resp:\n",
    "            content_type = resp.headers['Content-Type'].lower()\n",
    "            is_good_response = (resp.status_code == 200 \n",
    "                and content_type is not None \n",
    "                and content_type.find('html') > -1)\n",
    "            if is_good_response:\n",
    "                return resp.content\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "    except RequestException as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "words = []\n",
    "\n",
    "for initial_letter in initial_letters:\n",
    "    print(initial_letter)\n",
    "    \n",
    "    # Get the max page number of that initial_letter\n",
    "    first_page_html = BeautifulSoup(get_html(ROOT_PATH + initial_letter), 'html.parser')\n",
    "    pager = first_page_html.select_one('.CtgryPg')\n",
    "    if pager == None: # There is only one page\n",
    "        page_max = 1\n",
    "    else: # There are multiple pages\n",
    "        page_max = int(pager.select('a')[-2].get_text())\n",
    "    \n",
    "    for page_number in range(1, page_max + 1):\n",
    "        print('page: ' + str(page_number))\n",
    "        html = BeautifulSoup(get_html(ROOT_PATH + initial_letter + '/' + str(page_number)), 'html.parser')\n",
    "        for li in html.select_one('.CtgryUlL').select('li') + html.select_one('.CtgryUlR').select('li'):\n",
    "            original_word = li.get_text()\n",
    "            katakana_word = hiragana2katakana(original_word)\n",
    "            if has_katakana_only(katakana_word) and (len(words) == 0 or words[-1][1] != katakana_word):\n",
    "                words.append([original_word, katakana_word])\n",
    "        time.sleep(0.1)\n",
    "\n",
    "print(words[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list into a pandas DataFrame and save it\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(words)\n",
    "df.to_csv('dic/practical.csv', encoding='utf-8', header=None, index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
